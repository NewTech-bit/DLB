{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLB_FinalDataChallenge_XL_V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NewTech-bit/DLB/blob/AK_1/DLB_FinalDataChallenge_XL_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr9Fr2SRyM8K"
      },
      "source": [
        "This notebook is the final data challenge project for Deep Learning Datacamp at HSLU in September 2021. It's a group project conducted by Andreas Kl√§usli, Kevin Bollier, Ricky Roy Bruderer, and Xiying Liu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxFVr_zg1uYl"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWQ5h7AG1vHk"
      },
      "source": [
        "import os\n",
        "import os.path\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import random\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import IPython.display as display\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8nQuNgV2E0p",
        "outputId": "ec487ff6-bc21-4452-8146-b08521184ed4"
      },
      "source": [
        "# print(len([name for name in os.listdir('.') if os.path.isfile(name)]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf1254NC2F13",
        "outputId": "0f1f383e-2117-44d8-8745-a14739ffb601"
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrGAMI6hy1Yl"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiaDN4Khy16r"
      },
      "source": [
        "Data is uploaded by accessing files in Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS1NZQ0vx4pG",
        "outputId": "6c51b40b-6c7d-48bc-bf45-aa1365b63f29"
      },
      "source": [
        "# mount google drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcX3p08mzMPB"
      },
      "source": [
        "train_path = '/content/drive/MyDrive/DLB/training_data'\n",
        "test_path = '/content/drive/MyDrive/DLB/validation_data'\n",
        "train_dir = pathlib.Path(train_path)\n",
        "test_dir = pathlib.Path(test_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB1ujIhclks-",
        "outputId": "ad495259-120f-4c38-f67d-c1b0419ebfb8"
      },
      "source": [
        "train_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/DLB/training_data')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaRZE7opFGC8"
      },
      "source": [
        "# builder = tfds.ImageFolder(test_path)\n",
        "# print(builder.info)\n",
        "# ds = builder.as_dataset(shuffle_files=True)\n",
        "# # tfds.show_examples(ds, builder.info)\n",
        "# tfds.show_examples(ds, ds_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEBWTjfwD7AU",
        "outputId": "df5786da-efaa-4558-89d1-7aa07a9e080b"
      },
      "source": [
        "train_image_count = len(list(train_dir.glob('*.jpg')))\n",
        "test_image_count = len(list(test_dir.glob('*.jpg')))\n",
        "print(\"Number of images in training dataset: \", train_image_count)\n",
        "print(\"Number of images in testing dataset: \", test_image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in training dataset:  0\n",
            "Number of images in testing dataset:  985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMFxquqcIsqv",
        "outputId": "f658545e-446c-4bab-b2d3-089639bc7eaa"
      },
      "source": [
        "cats_train = list(train_dir.glob('cat.*.jpg'))\n",
        "dogs_train = list(train_dir.glob('dog.*.jpg'))\n",
        "cats_test = list(test_dir.glob('cat.*.jpg'))\n",
        "dogs_test = list(test_dir.glob('dog.*.jpg'))\n",
        "\n",
        "\n",
        "cats_train_count = len(cats_train)\n",
        "dogs_train_count = len(dogs_train)\n",
        "cats_test_count = len(cats_test)\n",
        "dogs_test_count = len(dogs_test)\n",
        "print(\"Number of cat images in training: \", cats_train_count)\n",
        "print(\"Number of dog images in training: \", dogs_train_count)\n",
        "print('\\n')\n",
        "print(\"Number of cat images in testing: \", cats_test_count)\n",
        "print(\"Number of dog images in testing: \", dogs_test_count)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cat images in training:  0\n",
            "Number of dog images in training:  0\n",
            "\n",
            "\n",
            "Number of cat images in testing:  496\n",
            "Number of dog images in testing:  489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uoIYs5d51Gl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUkzGrT7La6F"
      },
      "source": [
        "# # define a function to count images\n",
        "# def count_image(file_dir, image_class):\n",
        "#   image_count = len(list(file_dir.glob('*.jpg')))\n",
        "#   image_class_count = len(list(file_dir.glob('image_class.*.jpg')))\n",
        "#   return image_count, image_class_count"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOW8dZQO0L2y"
      },
      "source": [
        "for image_path in list(train_dir.glob('*.jpg'))[:3]:\n",
        "  display.display(PIL.Image.open(str(image_path)))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF91oqXI88ru"
      },
      "source": [
        "### Preprocessing for ingestion in keras.preprocessing flow\n",
        "https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqvsmo2cBWNW"
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWljnYni56ZR"
      },
      "source": [
        "# restructure train folder into subfolders cat and dog; move labelled files into\n",
        "# subfolders\n",
        "def create_subfolders(root_path, labels):\n",
        "  \"\"\"\n",
        "  creates subfolders for each category within the root_path folder\n",
        "  :param root_path: string path with dataset in it\n",
        "  :param labels: list of category labels\n",
        "  \"\"\"\n",
        "  root = pathlib.Path(root_path)\n",
        "  path_list = []\n",
        "  for label in labels:\n",
        "    train_label_path = root_path+\"/\"+label\n",
        "    path_list.append(train_label_path)\n",
        "    try:\n",
        "      pathlib.Path(train_label_path).mkdir(parents=True, exist_ok=False)\n",
        "    except FileExistsError:\n",
        "      print(\"Folder {} is already there\".format(train_label_path))\n",
        "    else:\n",
        "      print(\"Folder {} was created\".format(train_label_path))\n",
        "    print(path_list)\n",
        "  return path_list\n",
        "\n",
        "def files_to_subfolders(root_path, labels, path_list):\n",
        "  \"\"\"\n",
        "  moves files into the subfolders based on filenames 'cat.XXX.jpg'\n",
        "  :root_path: path within datasets are located\n",
        "  :param labels: list of category labels\n",
        "  :param path_list: list of subfolder paths\n",
        "  \"\"\"\n",
        "  root = pathlib.Path(root_path)\n",
        "  cont_var = 0\n",
        "  for folder in path_list:\n",
        "    path = pathlib.Path(folder)\n",
        "    if len(list(path.glob('*.*'))) == 0:\n",
        "      print(\"Folder {} is empty, process is ongoing\".format(folder))\n",
        "    else:\n",
        "      print(\"Folder {} is not empty, check content of the folder\".format(folder))\n",
        "      cont_var = 1\n",
        "  if cont_var == 0:\n",
        "    for file in root.glob('*.*.jpg'):\n",
        "      folder_name = file.stem.split(\".\", 1)[0]\n",
        "      file.rename(root /folder_name / file.name)\n",
        "      \n",
        "  else:\n",
        "    print(\"Files could not have been moved to training subfolders\")\n"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbJMSag-Q0z5",
        "outputId": "78e9c8ce-b845-4fd4-fa06-6ae834e6b85c"
      },
      "source": [
        "root_path=train_path\n",
        "labels=['cat','dog']\n",
        "t = create_subfolders(root_path=root_path, labels = labels)\n",
        "files_to_subfolders(root_path=root_path, labels = labels, path_list=t)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder /content/drive/MyDrive/DLB/training_data/cat is already there\n",
            "['/content/drive/MyDrive/DLB/training_data/cat']\n",
            "Folder /content/drive/MyDrive/DLB/training_data/dog is already there\n",
            "['/content/drive/MyDrive/DLB/training_data/cat', '/content/drive/MyDrive/DLB/training_data/dog']\n",
            "Folder /content/drive/MyDrive/DLB/training_data/cat is not empty, check content of the folder\n",
            "Folder /content/drive/MyDrive/DLB/training_data/dog is not empty, check content of the folder\n",
            "Files could not been moved to subfolder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnpfIp8mRgH9"
      },
      "source": [
        ""
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfCC1TaA56ie"
      },
      "source": [
        "# generate validation for training (10 %) per category\n",
        "# create validation folder DLB/train_val \n",
        "\n",
        "def create_train_val(dest_path, frac, path_list, labels, seed):\n",
        "  \"\"\"\n",
        "  creates folder for training validation with fraction of files per category \n",
        "  within\n",
        "  :param dest_path: path of training validation datasets\n",
        "  :param frac: random fraction per category\n",
        "  :param path_list: list of paths containing datasets per category\n",
        "  :param seed:\n",
        "  \"\"\"\n",
        "# create folder for training validation if not exists\n",
        "  try:\n",
        "    pathlib.Path(dest_path).mkdir(parents=True, exist_ok=False)\n",
        "  except FileExistsError:\n",
        "    print(\"Folder {} already exists\".format(dest_path))\n",
        "  else:\n",
        "    print(\"Folder {} created\".format(dest_path))\n",
        "# create subfolders per category\n",
        "  l_path = create_subfolders(dest_path, labels)\n",
        "\n",
        "# move fraction of randomised files into subfolders\n",
        "  random.seed(seed)\n",
        "  for path in path_list:\n",
        "    filenames = random.sample(os.listdir(path), int(frac*len(list(pathlib.Path(path).glob('*.*')))))\n",
        "    print(\"Number of randomised files from {0}: {1}\".format(path, len(filenames)))\n",
        "    for fname in filenames:\n",
        "      srcpath = os.path.join(path, fname)\n",
        "      reg =re.findall(r'^\\w+', fname)[0]\n",
        "      dst_path = dest_path+\"/\"+reg\n",
        "      despath = os.path.join(dst_path, fname)\n",
        "      shutil.copyfile(str(srcpath), str(despath))\n",
        "      del dst_path\n",
        "  print(\"train_val generated.\")"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3_Qe2lyF6U7",
        "outputId": "a718e0ef-280f-4a9a-ec0d-aca169c51c72"
      },
      "source": [
        "create_train_val(dest_path=\"/content/drive/MyDrive/DLB/train_val\", frac=0.1, seed=5, path_list = t, labels = labels)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder /content/drive/MyDrive/DLB/train_val created\n",
            "Folder /content/drive/MyDrive/DLB/train_val/cat was created\n",
            "['/content/drive/MyDrive/DLB/train_val/cat']\n",
            "Folder /content/drive/MyDrive/DLB/train_val/dog was created\n",
            "['/content/drive/MyDrive/DLB/train_val/cat', '/content/drive/MyDrive/DLB/train_val/dog']\n",
            "Number of randomised files from /content/drive/MyDrive/DLB/training_data/cat: 150\n",
            "Number of randomised files from /content/drive/MyDrive/DLB/training_data/dog: 140\n",
            "train_val generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdi4qRNmTil4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHvFjeGK8Rwt"
      },
      "source": [
        "\n"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1q00gsR9muj"
      },
      "source": [
        "\n",
        "  "
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y42vXd7_SMa"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jgqQYnW_Sol"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMrxfH2G0MVT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MOaWV_d1Qmc"
      },
      "source": [
        "## Load data\n",
        "\n",
        "Using `tf.data.Dataset`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJLsyx4e4NOE"
      },
      "source": [
        "Define some parameters for the loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BePK00nB0eTp"
      },
      "source": [
        "batch_size = 17\n",
        "img_height = 200\n",
        "img_width = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "2p5sQXcDPhMD",
        "outputId": "87831671-408e-4ec3-ae29-9d0d56c9ddee"
      },
      "source": [
        "# show random five images from training dataset\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "for i in range(5):\n",
        "  file = random.choice(os.listdir(train_path))\n",
        "  image_path = os.path.join(train_path, file)\n",
        "  img = mpimg.imread(image_path)\n",
        "  ax = plt.subplot(1, 5, i+1)\n",
        "  ax.title.set_text(file)\n",
        "  plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-bb987157f294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/DLB/training_data'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S4-TW2FIP6s9",
        "outputId": "8475b0b3-1f0c-467e-ec1f-090832c50d12"
      },
      "source": [
        "os.listdir(test_path)[3] # check naming convention of images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dog.4713.jpg'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlPTdVUBNrmt"
      },
      "source": [
        "# setting parameters for loading the dataset\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "# train_path = '/content/drive/MyDrive/DLB/training_data'\n",
        "# test_path = '/content/drive/MyDrive/DLB/validation_data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6Iqdt6HPHVn"
      },
      "source": [
        "# creating the image data and the labels\n",
        "\n",
        "def create_dataset(img_folder):\n",
        "  img_data_array=[]\n",
        "  class_name=[]\n",
        "\n",
        "  for file in os.listdir(img_folder):\n",
        "    image_path = os.path.join(img_folder, file)\n",
        "    cls_name = file[:3]\n",
        "    image = cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH), interpolation=cv2.INTER_AREA)\n",
        "    image = np.array(image)\n",
        "    image = image.astype('float32')\n",
        "    image = image / 255.0\n",
        "    img_data_array.append(image)\n",
        "    class_name.append(cls_name)\n",
        "  \n",
        "  return img_data_array, class_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEbZ2UBUViUz"
      },
      "source": [
        "# create test dataset with (image, lable) pairs, takes ~6 mins\n",
        "test_image, test_label = create_dataset(test_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaV4wFkiYFFq"
      },
      "source": [
        "# create train dataset with (image, lable) pairs, takes ~17 mins\n",
        "train_image, train_label = create_dataset(train_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrtGEFHxYdBf"
      },
      "source": [
        "def class_encode(label):\n",
        "  target_dict = {k:v for v, k in enumerate(np.unique(label))}\n",
        "  target_value = [target_dict[label[i]] for i in range(len(label))]\n",
        "  return target_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "7l__ep04dP9h",
        "outputId": "2bcad4ce-1cba-4b78-c121-df88a507fd38"
      },
      "source": [
        "train_label = class_encode(train_label)\n",
        "test_label = class_encode(test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3501b9e0c426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'class_encode' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUBGLq9Hd2R0"
      },
      "source": [
        "## Create deep learning models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdzIW8qmfClr"
      },
      "source": [
        "input_shape=(64,64,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETorDtoqdqvy"
      },
      "source": [
        "# # build a convolutional neural network withouth image argumentation\n",
        "# def func_model():\n",
        "#   input_layer = tf.keras.Input(shape=input_shape) # instantiate the input layer\n",
        "\n",
        "#   x = Conv2D(16, (3,3), activation='relu')(input_layer) # stack layers using the functional API syntax\n",
        "#   x = MaxPooling2D(2,2)\n",
        "#   x = Conv2D(32, (3,3), activation='relu')(x)\n",
        "#   x = MaxPooling2D(2,2)\n",
        "#   x = Flatten()(x)\n",
        "#   x = Dense(128, activation='relu')(x)\n",
        "\n",
        "#   output_layer = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "#   func_model = Model(inputs = input_layer, outputs=output_layer) # declare inputs and outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1NUz0B_pNvN"
      },
      "source": [
        "### 1. Baseline CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPr6sAikkIA3"
      },
      "source": [
        "def model_conv():\n",
        "  model = Sequential([Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n",
        "                      MaxPooling2D(2,2),\n",
        "                      Conv2D(64, (3,3), activation='relu'),\n",
        "                      MaxPooling2D(2,2),\n",
        "                      Flatten(),\n",
        "                      Dense(128, activation='relu'),\n",
        "                      Dense(1, activation='sigmoid')  \n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "bMvXWLF-hHX8",
        "outputId": "2c457bc5-b60d-4604-a52e-6173ac42b1f8"
      },
      "source": [
        "model = func_model()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a3fb3e258f0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model.compile(loss='binary_crossentropy',\n\u001b[1;32m      3\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               metrics=['accuracy'])\n",
            "\u001b[0;32m<ipython-input-18-d717a6ba5aa3>\u001b[0m in \u001b[0;36mfunc_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# instantiate the input layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# stack layers using the functional API syntax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 977\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1115\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2632\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2634\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2635\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    232\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d_6 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 64, 64)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6N0YKpQhvvW",
        "outputId": "6be34df1-044b-448f-f377-e40fc6b1ec92"
      },
      "source": [
        "# flow images in batches of 20 using _datagen generator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "image_size = (150, 150)\n",
        "train_generator = train_datagen.flow_from_directory(train_path,\n",
        "                                                    target_size=image_size,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "test_generator = test_datagen.flow_from_directory(test_path,\n",
        "                                                   target_size=image_size,\n",
        "                                                   batch_size=20,\n",
        "                                                   class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VTp5aIUl1t8"
      },
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=171, # 2907 images = batch_size 17 * steps 171\n",
        "    epochs = 15,\n",
        "    validation_data= validation_generator,\n",
        "    validation_steps=58,\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfuwtZM3ln1b"
      },
      "source": [
        "# plot results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legen()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NPMgSQfpTZw"
      },
      "source": [
        "### CNN model with image augmentation\n",
        "-> to be completed: data_augmentation with preprocessing flow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aOjER3VW-09"
      },
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxC_gWVwXBFR"
      },
      "source": [
        "inputs = keras.Input(shape=input_shape)\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUIWHqCqpX78"
      },
      "source": [
        "def model_conv2():\n",
        "  model = Sequential([Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n",
        "                      MaxPooling2D(2,2),\n",
        "                      Conv2D(64, (3,3), activation='relu'),\n",
        "                      MaxPooling2D(2,2),\n",
        "                      Flatten(),\n",
        "                      Dense(128, activation='relu'),\n",
        "                      Dense(1, activation='sigmoid')\n",
        " \n",
        "  ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKeQMTZ0rGlJ"
      },
      "source": [
        "inputs = keras.Input(shape=input_shape)\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1pk3-r4rG8B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIWCRJ0brHap"
      },
      "source": [
        "### Transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEIrK_D0rJbQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSr1RkslradQ"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nISHvHAyrb0i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}